{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Stavanger DAT550 - Data Mining and Deep Learning\n",
    "## Hands-on 10: Text classification using LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from keras_preprocessing import sequence\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "number_of_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (x_test, y_test)  = imdb.load_data(num_words = number_of_words)\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "oov_id = 2\n",
    "index_offset = 2\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=number_of_words, start_char=start_id,\n",
    "                                                                        oov_char=oov_id, index_from=index_offset)\n",
    " \n",
    "\n",
    "word2idx = tf.keras.datasets.imdb.get_word_index()\n",
    " \n",
    "idx2word = {v + index_offset: k for k, v in word2idx.items()}\n",
    " \n",
    "idx2word[pad_id] = '<PAD>'\n",
    "idx2word[start_id] = '<START>'\n",
    "idx2word[oov_id] = '<OOV>'\n",
    " \n",
    "rnn_cell_size = max_len\n",
    " \n",
    "x_train = sequence.pad_sequences(x_train,\n",
    "                                 maxlen=max_len,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len,\n",
    "                                truncating='post',\n",
    "                                padding='post',\n",
    "                                value=pad_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly fishing was\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertIntToWord(sentence):\n",
    "    sentence_str = ''\n",
    "    for word in sentence:\n",
    "            sentence_str = sentence_str + ' ' + idx2word[word]\n",
    "    return sentence_str\n",
    "convertIntToWord(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkset = set()\n",
    "for x in x_train:\n",
    "    for wordid in x:\n",
    "        word = idx2word[wordid]\n",
    "        if word not in embeddings_index:\n",
    "                unkset.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unkset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "embedding_size = 100\n",
    "GLOVE_DIR='/Users/vsetty/repos/BRENDA-new/new-extension/BRENDA/Server/model/static/glove/'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word2idx) + 1, embedding_size))\n",
    "for word, i in word2idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(number_of_words, embedding_size, \n",
    "                                            input_length=max_len, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=100,  activation='tanh')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,161,001\n",
      "Trainable params: 1,161,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 54s 2ms/sample - loss: 0.4806 - accuracy: 0.7730\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 50s 2ms/sample - loss: 0.3338 - accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155ca1208>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 17s 673us/sample - loss: 0.4111 - accuracy: 0.8106\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 100)          8858500   \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 9,019,501\n",
      "Trainable params: 9,019,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 73s 3ms/sample - loss: 0.6552 - accuracy: 0.6032\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 71s 3ms/sample - loss: 0.4813 - accuracy: 0.7740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14eaba710>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(len(word2idx) + 1,\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=True)\n",
    "model_with_pretrained_vec = tf.keras.Sequential()\n",
    "model_with_pretrained_vec.add(embedding_layer)\n",
    "model_with_pretrained_vec.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=100,  activation='tanh')))\n",
    "model_with_pretrained_vec.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model_with_pretrained_vec.summary()\n",
    "model_with_pretrained_vec.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_with_pretrained_vec.fit(x_train, y_train, epochs=2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 17s 672us/sample - loss: 0.4382 - accuracy: 0.7918\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_with_pretrained_vec.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2x",
   "language": "python",
   "name": "tf2x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
